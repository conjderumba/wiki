{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to my personal WiKi You can find some useful commands and procedures","title":"Introduction"},{"location":"#welcome-to-my-personal-wiki","text":"You can find some useful commands and procedures","title":"Welcome to my personal WiKi"},{"location":"aws/","text":"AWS This section contains some tricks, procedures and configurations for some AWS services S3 Mount S3 Bucket on linux # Install prerequisites yum install automake fuse fuse-devel gcc-c++ git libcurl-devel libxml2-devel make openssl-devel -y # Create mountpoint cd /srv mkdir s3fs cd s3fs/ # Obtain s3fs-fuse. sudo amazon-linux-extras install epel sudo yum install s3fs-fuse Cloudformation Curl for cancel jobs In a Lambda python code you can print this curl to cancel the CloudFormation Stack, in case it remains in a IN PROGRESS state # CF Parameters to build the response in case of Stack blocking ServiceToken = event[ 'ServiceToken' ] StackId = event[ 'StackId' ] RequestId = event[ 'RequestId' ] LogicalResourceId = event[ 'LogicalResourceId' ] ResponseURL = event[ 'ResponseURL' ] # CloudFormation CURL response. Uncomment while testing logger . info( 'CloudFormation CURL response. Uncomment while testing' ) logger . info( \"curl -H 'Content-Type: ''' -X PUT -d '{ \\\" Status \\\" : \\\" SUCCESS \\\" , \\\" PhysicalResourceId \\\" : \\\" \" + physical_resource_id + \" \\\" , \\\" StackId \\\" : \\\" \" + StackId + \" \\\" , \\\" RequestId \\\" : \\\" \" + RequestId + \" \\\" , \\\" LogicalResourceId \\\" : \\\" \" + LogicalResourceId + \" \\\" }' '\" + ResponseURL + \"'\" )","title":"AWS"},{"location":"aws/#aws","text":"This section contains some tricks, procedures and configurations for some AWS services","title":"AWS"},{"location":"aws/#s3","text":"","title":"S3"},{"location":"aws/#mount-s3-bucket-on-linux","text":"# Install prerequisites yum install automake fuse fuse-devel gcc-c++ git libcurl-devel libxml2-devel make openssl-devel -y # Create mountpoint cd /srv mkdir s3fs cd s3fs/ # Obtain s3fs-fuse. sudo amazon-linux-extras install epel sudo yum install s3fs-fuse","title":"Mount S3 Bucket on linux"},{"location":"aws/#cloudformation","text":"","title":"Cloudformation"},{"location":"aws/#curl-for-cancel-jobs","text":"In a Lambda python code you can print this curl to cancel the CloudFormation Stack, in case it remains in a IN PROGRESS state # CF Parameters to build the response in case of Stack blocking ServiceToken = event[ 'ServiceToken' ] StackId = event[ 'StackId' ] RequestId = event[ 'RequestId' ] LogicalResourceId = event[ 'LogicalResourceId' ] ResponseURL = event[ 'ResponseURL' ] # CloudFormation CURL response. Uncomment while testing logger . info( 'CloudFormation CURL response. Uncomment while testing' ) logger . info( \"curl -H 'Content-Type: ''' -X PUT -d '{ \\\" Status \\\" : \\\" SUCCESS \\\" , \\\" PhysicalResourceId \\\" : \\\" \" + physical_resource_id + \" \\\" , \\\" StackId \\\" : \\\" \" + StackId + \" \\\" , \\\" RequestId \\\" : \\\" \" + RequestId + \" \\\" , \\\" LogicalResourceId \\\" : \\\" \" + LogicalResourceId + \" \\\" }' '\" + ResponseURL + \"'\" )","title":"Curl for cancel jobs"},{"location":"linux/","text":"Generic Did you forget to sudo vi? :w !sudo tee \"%\" Find and kill processes with certain name for pid in $( ps -aux | grep \"<eg: python follower>\" | awk { 'print $2' } ) ; do kill $pid; done Add and delete Linux users with PEM Add user sudo adduser <username> sudo su <username> cd mkdir .ssh chmod 700 .ssh cd touch .ssh/authorized_keys chmod 600 .ssh/authorized_keys #A\u00d1ADIR LA CLAVE QUE QUERAMOS, cuidado con los saltos de l\u00ednea, tiene que ir todo en una sola linea echo \"ssh-rsa yStyZ7kEuyhgD3U/bqRyFFlOEB/6TGpKTv3V8GgrMa8evVO8l34563trfeafewa525rV58vp1N5TSMpxl0+CWchCkimBx6Fo2meFm7xqR7Z fffff\" >> ~/.ssh/authorized_keys Delete user sudo userdel -r <userame> Home - End keys not working on oh-my-zsh Add this to ~/.zshrc bindkey \"^[[1~\" beginning-of-line bindkey \"^[[4~\" end-of-line Oracle Visualization > sqplus / as sysdba SQL > set lines 300 pages 30000 SQL > select * from v$instance; Import and Export Schema For both import and export process, the folder must exists both defined as Oracle directories and in the filesystem. Import Note The schema will be created if it doesn't exists, and it should have the same password as the origin schema. SQL > impdp sys / pass remap_schema = SOURCE_SCHEMA:DEST_SCHEMA directory = exp_dir dumpfile = DUMP_FILENAME.dmp logfile = impdp_DUMP_FILENAME.log Export SQL > expdp SCHEMA_TO_EXPORT / PASSWORD directory = exp_dir dumpfile = DUMP_FILENAME.dmp logfile = export_DUMP_FILENAME.log filesize = 1 g Show active databases SQL > SELECT INSTANCE_NAME, DATABASE_STATUS, INSTANCE_ROLE from v$instance;","title":"Linux"},{"location":"linux/#generic","text":"","title":"Generic"},{"location":"linux/#did-you-forget-to-sudo-vi","text":":w !sudo tee \"%\"","title":"Did you forget to sudo vi?"},{"location":"linux/#find-and-kill-processes-with-certain-name","text":"for pid in $( ps -aux | grep \"<eg: python follower>\" | awk { 'print $2' } ) ; do kill $pid; done","title":"Find and kill processes with certain name"},{"location":"linux/#add-and-delete-linux-users-with-pem","text":"","title":"Add and delete Linux users with PEM"},{"location":"linux/#add-user","text":"sudo adduser <username> sudo su <username> cd mkdir .ssh chmod 700 .ssh cd touch .ssh/authorized_keys chmod 600 .ssh/authorized_keys #A\u00d1ADIR LA CLAVE QUE QUERAMOS, cuidado con los saltos de l\u00ednea, tiene que ir todo en una sola linea echo \"ssh-rsa yStyZ7kEuyhgD3U/bqRyFFlOEB/6TGpKTv3V8GgrMa8evVO8l34563trfeafewa525rV58vp1N5TSMpxl0+CWchCkimBx6Fo2meFm7xqR7Z fffff\" >> ~/.ssh/authorized_keys","title":"Add user"},{"location":"linux/#delete-user","text":"sudo userdel -r <userame>","title":"Delete user"},{"location":"linux/#home-end-keys-not-working-on-oh-my-zsh","text":"Add this to ~/.zshrc bindkey \"^[[1~\" beginning-of-line bindkey \"^[[4~\" end-of-line","title":"Home - End keys not working on oh-my-zsh"},{"location":"linux/#oracle","text":"","title":"Oracle"},{"location":"linux/#visualization","text":"> sqplus / as sysdba SQL > set lines 300 pages 30000 SQL > select * from v$instance;","title":"Visualization"},{"location":"linux/#import-and-export-schema","text":"For both import and export process, the folder must exists both defined as Oracle directories and in the filesystem.","title":"Import and Export Schema"},{"location":"linux/#import","text":"Note The schema will be created if it doesn't exists, and it should have the same password as the origin schema. SQL > impdp sys / pass remap_schema = SOURCE_SCHEMA:DEST_SCHEMA directory = exp_dir dumpfile = DUMP_FILENAME.dmp logfile = impdp_DUMP_FILENAME.log","title":"Import"},{"location":"linux/#export","text":"SQL > expdp SCHEMA_TO_EXPORT / PASSWORD directory = exp_dir dumpfile = DUMP_FILENAME.dmp logfile = export_DUMP_FILENAME.log filesize = 1 g","title":"Export"},{"location":"linux/#show-active-databases","text":"SQL > SELECT INSTANCE_NAME, DATABASE_STATUS, INSTANCE_ROLE from v$instance;","title":"Show active databases"},{"location":"stylesheets/mkdocs-material-dark-theme/","text":"mkdocs-material-dark-theme External SCSS/CSS file that can change the appearance of mkdocs-material theme and render it in dark colors. To have proper syntax highlighting, don't forget to add this code to your mkdocs.yml file: markdown_extensions : - codehilite : guess_lang : False use_pygments : True noclasses : True pygments_style : monokai","title":"mkdocs-material-dark-theme"},{"location":"stylesheets/mkdocs-material-dark-theme/#mkdocs-material-dark-theme","text":"External SCSS/CSS file that can change the appearance of mkdocs-material theme and render it in dark colors. To have proper syntax highlighting, don't forget to add this code to your mkdocs.yml file: markdown_extensions : - codehilite : guess_lang : False use_pygments : True noclasses : True pygments_style : monokai","title":"mkdocs-material-dark-theme"}]}